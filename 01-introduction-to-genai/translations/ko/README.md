# 생성형 AI와 대규모 언어 모델 소개

[![생성형 AI와 대규모 언어 모델 소개](../../images/01-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson-1-gh?WT.mc_id=academic-105485-koreyst)

_(위 이미지를 클릭하면 이 수업의 영상을 볼 수 있어요)_

생성형 AI는 텍스트, 이미지 그리고 다른 종류의 콘텐츠를 만들어낼 수 있는 인공지능이에요. 이 기술이 정말 대단한 이유는 AI를 누구나 쉽게 사용할 수 있게 만들었다는 거예요. 그저 자연어로 된 문장, 즉 텍스트 프롬프트만 있으면 누구나 사용할 수 있죠. 뭔가 의미 있는 일을 하기 위해 Java나 SQL 같은 언어를 배울 필요가 없어요. 그냥 여러분의 언어로 원하는 걸 말하면, AI 모델이 제안을 해줄 거예요. 이게 가져올 응용과 영향은 엄청나요. 보고서를 작성하거나 이해하고, 애플리케이션을 만들고 더 많은 일을 몇 초 만에 할 수 있게 되는 거죠.

이 커리큘럼에서는 우리 스타트업이 어떻게 생성형 AI를 활용해 교육 분야에서 새로운 시나리오를 열어가는지, 그리고 이 기술의 적용에 따른 사회적 영향과 기술적 한계라는 피할 수 없는 도전들을 어떻게 다루는지 살펴볼 거예요.

## 소개

이 수업에서는 다음 내용을 다룰 거예요:

- 비즈니스 시나리오 소개: 우리 스타트업의 아이디어와 미션
- 생성형 AI와 우리가 현재의 기술 상황에 도달하게 된 과정
- 대규모 언어 모델의 내부 작동 원리
- 대규모 언어 모델의 주요 기능과 실용적인 사용 사례

## 학습 목표

이 수업을 마치면 여러분은 다음을 이해하게 될 거예요:

- 생성형 AI가 무엇이고 대규모 언어 모델이 어떻게 작동하는지
- 교육 시나리오에 중점을 두고, 다양한 사용 사례에 대규모 언어 모델을 어떻게 활용할 수 있는지

## 시나리오: 우리의 교육 스타트업

생성형 인공지능(AI)은 AI 기술의 정점을 나타내며, 한때 불가능하다고 여겨졌던 것들의 경계를 넓히고 있어요. 생성형 AI 모델은 여러 가지 능력과 응용 분야를 가지고 있지만, 이 커리큘럼에서는 가상의 스타트업을 통해 교육을 어떻게 혁신하고 있는지 살펴볼 거예요. 이 스타트업을 *우리 스타트업*이라고 부를게요. 우리 스타트업은 교육 분야에서 일하며, 야심 찬 미션 선언문을 가지고 있어요.

> _전 세계적으로 학습 접근성을 개선하고, 교육에 대한 공평한 접근을 보장하며, 모든 학습자에게 그들의 필요에 맞는 개인화된 학습 경험을 제공한다._

우리 스타트업 팀은 현대의 가장 강력한 도구 중 하나인 대규모 언어 모델(LLM)을 활용하지 않고는 이 목표를 달성할 수 없다는 걸 알고 있어요.

생성형 AI는 오늘날 우리가 배우고 가르치는 방식을 혁신할 것으로 예상돼요. 학생들은 24시간 내내 엄청난 양의 정보와 예시를 제공하는 가상 선생님을 이용할 수 있고, 선생님들은 혁신적인 도구를 활용해 학생들을 평가하고 피드백을 줄 수 있게 될 거예요.

![다섯 명의 젊은 학생들이 모니터를 보고 있는 모습 - DALLE2가 생성한 이미지](../../images/students-by-DALLE2.png?WT.mc_id=academic-105485-koreyst)

먼저, 이 커리큘럼 전체에서 사용할 몇 가지 기본 개념과 용어를 정의해 볼게요.

## 생성형 AI는 어떻게 탄생했나요?

최근 생성형 AI 모델의 발표로 엄청난 '열풍'이 일고 있지만, 사실 이 기술은 수십 년에 걸쳐 만들어진 거예요. 첫 연구는 60년대로 거슬러 올라가죠. 이제 우리는 AI가 인간의 인지 능력을 가지게 된 시점에 와 있어요. 예를 들어 [OpenAI ChatGPT](https://openai.com/chatgpt)나 [Bing Chat](https://www.microsoft.com/edge/features/bing-chat?WT.mc_id=academic-105485-koreyst)이 보여주는 대화 능력 같은 거죠. Bing Chat도 웹 검색 대화에 GPT 모델을 사용해요.

조금 더 거슬러 올라가면, AI의 첫 프로토타입은 타자로 작성된 챗봇이었어요. 이건 전문가 그룹에서 추출한 지식 베이스를 컴퓨터에 표현한 거였죠. 지식 베이스의 답변은 입력 텍스트에 나타나는 키워드에 의해 트리거됐어요.

하지만 곧 이런 타자로 작성된 챗봇 방식은 잘 확장되지 않는다는 게 분명해졌어요.

### AI에 대한 통계적 접근: 머신 러닝

90년대에 텍스트 분석에 통계적 접근법을 적용하면서 전환점이 왔어요. 이로 인해 머신 러닝이라고 불리는 새로운 알고리즘이 개발됐죠. 이 알고리즘은 명시적으로 프로그래밍되지 않고도 데이터에서 패턴을 학습할 수 있어요. 이 접근법은 기계가 인간의 언어 이해를 시뮬레이션할 수 있게 해줘요. 텍스트-라벨 쌍으로 통계 모델을 훈련시키면, 모델이 알려지지 않은 입력 텍스트를 메시지의 의도를 나타내는 미리 정의된 라벨로 분류할 수 있게 되는 거죠.

### 신경망과 현대의 가상 어시스턴트

최근에는 하드웨어의 기술적 발전으로 더 많은 양의 데이터와 더 복잡한 계산을 처리할 수 있게 됐어요. 이로 인해 AI 분야의 연구가 촉진되어 신경망 또는 딥러닝 알고리즘이라고 불리는 고급 머신 러닝 알고리즘이 개발됐죠.

신경망(특히 순환 신경망 - RNN)은 자연어 처리를 크게 향상시켰어요. 문장에서 단어의 맥락을 중요하게 여기면서 텍스트의 의미를 더 의미 있는 방식으로 표현할 수 있게 된 거죠.

이게 바로 새 세기의 첫 10년에 탄생한 가상 비서의 기반 기술이에요. 이 가상 비서들은 인간의 언어를 해석하고, 필요를 파악하고, 그 필요를 충족시키기 위한 행동을 수행하는 데 아주 능숙해요. 예를 들어 미리 정의된 스크립트로 답변하거나 제3자 서비스를 이용하는 식이죠.

### 현재의 생성형 AI

그래서 우리는 오늘날 생성형 AI에 이르게 됐어요. 이건 딥러닝의 하위 집합으로 볼 수 있죠.

![AI, ML, DL 그리고 생성형 AI](../../images/AI-diagram.png?WT.mc_id=academic-105485-koreyst)

AI 분야에서 수십 년간의 연구 끝에 '_트랜스포머_'라고 불리는 새로운 모델 아키텍처가 등장했어요. 이건 RNN의 한계를 극복하고 훨씬 더 긴 텍스트 시퀀스를 입력으로 받을 수 있게 됐죠. 트랜스포머는 어텐션 메커니즘을 기반으로 해요. 이 메커니즘은 모델이 받는 입력에 서로 다른 가중치를 줄 수 있게 해주는데, 텍스트 시퀀스의 순서와 상관없이 가장 관련 있는 정보가 집중된 곳에 '더 많은 주의를 기울이게' 해줘요.

최근의 대부분 생성형 AI 모델들 - 텍스트 입력과 출력을 다루기 때문에 대규모 언어 모델(LLM)이라고도 불러요 - 은 실제로 이 아키텍처를 기반으로 하고 있어요. 이 모델들의 흥미로운 점은 책, 기사, 웹사이트 등 다양한 출처에서 가져온 엄청난 양의 라벨이 없는 데이터로 훈련되었다는 거예요. 그래서 다양한 작업에 적응할 수 있고 문법적으로 정확하면서도 창의성이 엿보이는 텍스트를 생성할 수 있죠. 즉, 기계가 입력 텍스트를 '이해'하는 능력을 믿을 수 없을 정도로 향상시켰을 뿐만 아니라, 인간의 언어로 독창적인 응답을 생성하는 능력도 가능하게 만든 거예요.

## 대규모 언어 모델은 어떻게 작동할까요?

다음 장에서 우리는 다양한 종류의 생성형 AI 모델을 살펴볼 거예요. 하지만 지금은 대규모 언어 모델이 어떻게 작동하는지 알아보죠. 특히 OpenAI GPT(생성 사전 훈련 트랜스포머) 모델에 초점을 맞춰볼게요.

- **토크나이저, 텍스트를 숫자로**: 대규모 언어 모델은 텍스트를 입력으로 받아 텍스트를 출력으로 생성해요. 하지만 이들은 통계 모델이기 때문에 텍스트 시퀀스보다 숫자를 다루는 게 훨씬 더 편해요. 그래서 모델의 모든 입력은 핵심 모델에 사용되기 전에 토크나이저에 의해 처리돼요. 토큰은 텍스트의 조각인데, 다양한 수의 문자로 구성돼 있어요. 토크나이저의 주요 작업은 입력을 토큰 배열로 나누는 거예요. 그런 다음, 각 토큰은 토큰 인덱스와 매핑되는데, 이건 원래 텍스트 조각을 정수로 인코딩한 거예요.

![토크나이저 예시](../../images/tokenizer-example.png?WT.mc_id=academic-105485-koreyst)

- **출력 토큰 예측하기**: n개의 토큰을 입력으로 받으면(최대 n은 모델마다 다르죠), 모델은 하나의 토큰을 출력으로 예측할 수 있어요. 이 토큰은 다음 반복의 입력에 포함되는데, 이런 확장 윈도우 패턴을 통해 사용자는 하나(또는 여러 개)의 문장을 답변으로 받는 더 나은 경험을 할 수 있어요. 이게 바로 여러분이 ChatGPT를 사용해 봤다면 때때로 문장 중간에서 멈추는 것처럼 보이는 이유를 설명해 주죠.

- **선택 과정, 확률 분포**: 출력 토큰은 현재 텍스트 시퀀스 다음에 올 확률에 따라 모델이 선택해요. 이는 모델이 모든 가능한 '다음 토큰'에 대한 확률 분포를 예측하기 때문이에요. 이 확률 분포는 모델의 훈련을 기반으로 계산돼요. 하지만 항상 가장 높은 확률을 가진 토큰이 결과 분포에서 선택되는 건 아니에요. 이 선택에는 일정 정도의 무작위성이 추가되는데, 이로 인해 모델이 비결정적인 방식으로 작동하게 돼요. 즉, 같은 입력에 대해 항상 똑같은 출력을 얻지는 않아요. 이런 무작위성은 창의적 사고 과정을 시뮬레이션하기 위해 추가되며, 온도라고 불리는 모델 매개변수를 사용해 조정할 수 있어요.

## 우리 스타트업은 대규모 언어 모델을 어떻게 활용할 수 있을까요?

이제 대규모 언어 모델의 내부 작동 원리를 더 잘 이해했으니, 우리 비즈니스 시나리오를 염두에 두고 이 모델들이 꽤 잘 수행할 수 있는 가장 일반적인 작업들의 실제 예를 살펴볼게요.

우리는 대규모 언어 모델의 주요 능력이 '자연어로 작성된 텍스트 입력에서 시작해 처음부터 텍스트를 생성하는 것'이라고 말했죠.

그런데 어떤 종류의 텍스트 입력과 출력일까요?

대규모 언어 모델의 입력은 프롬프트라고 알려져 있고, 출력은 컴플리션이라고 해요. 컴플리션은 현재 입력을 완성하기 위해 다음 토큰을 생성하는 모델 메커니즘을 가리키는 용어예요. 우리는 프롬프트가 무엇인지, 그리고 모델에서 최상의 결과를 얻기 위해 어떻게 설계해야 하는지 깊이 들어갈 거예요. 하지만 지금은 프롬프트에 다음과 같은 것들이 포함될 수 있다고만 말해둘게요:

- 모델에서 기대하는 출력 유형을 지정하는 **지시사항**. 이 지시사항에는 때때로 예시나 추가 데이터가 포함될 수 있어요.

  1. 기사, 책, 제품 리뷰 등의 요약과 함께 비정형 데이터에서 인사이트 추출하기.

  ![요약 예시](../../images/summarization-example.png?WT.mc_id=academic-105485-koreyst)

    <br>
    
    2. 기사, 에세이, 과제 등의 창의적인 아이디어 제시와 설계.
    
    ![창의적 글쓰기 예시](../../images/creative-writing-example.png?WT.mc_id=academic-105485-koreyst)

    <br>

- 에이전트와의 대화 형식으로 묻는 **질문**.

![대화 예시](../../images/conversation-example.png?WT.mc_id=academic-105485-koreyst)

<br>

- **완성해야 할 텍스트**를 제공함으로써 글쓰기 보조를 요청.

![텍스트 완성 예시](../../images/text-completion-example.png?WT.mc_id=academic-105485-koreyst)

<br>

- 설명과 문서화를 요청하는 **코드** 조각, 또는 특정 작업을 수행하는 코드 조각을 생성해 달라는 요청.

![코딩 예시](../../images/coding-example.png?WT.mc_id=academic-105485-koreyst)

<br>

위의 예시들은 꽤 간단하고 대규모 언어 모델의 능력을 완전히 보여주려는 것은 아니에요. 단지 생성형 AI를 사용하는 잠재력을 보여주려는 거죠. 특히 교육 맥락에 국한되지 않고요.

또한, 생성형 AI 모델의 출력은 완벽하지 않아요. 때때로 모델의 창의성이 오히려 역효과를 낼 수 있어서, 인간 사용자가 현실을 왜곡하거나 공격적인 것으로 해석할 수 있는 단어 조합이 결과로 나올 수 있어요. 생성형 AI는 지능적이지 않아요 - 적어도 비판적이고 창의적인 추론이나 감성 지능을 포함하는 더 포괄적인 지능의 정의에서는요. 결정론적이지 않고 신뢰할 수 없어요. 잘못된 참조, 내용, 진술 등의 조작이 정확한 정보와 결합되어 설득력 있고 자신감 있는 방식으로 제시될 수 있기 때문이죠. 다음 수업에서는 이런 모든 한계를 다루고 이를 완화하기 위해 무엇을 할 수 있는지 살펴볼 거예요.

## 과제

여러분의 과제는 [생성형 AI](https://en.wikipedia.org/wiki/Generative_artificial_intelligence?WT.mc_id=academic-105485-koreyst)에 대해 더 자세히 읽어보고, 현재 생성형 AI가 없는 분야 중 여러분이 생성형 AI를 추가하고 싶은 영역을 찾아보는 거예요. "옛날 방식"으로 하는 것과 비교해 어떤 영향이 다를까요? 이전에는 할 수 없었던 일을 할 수 있게 될까요, 아니면 더 빨라질까요? 여러분의 꿈의 AI 스타트업이 어떤 모습일지 300단어로 요약해 보세요. "문제", "AI를 어떻게 사용할 것인가", "영향" 그리고 선택적으로 사업 계획 같은 제목을 포함해 보세요.

이 과제를 완료했다면, 여러분은 Microsoft의 인큐베이터인 [Microsoft for Startups Founders Hub](https://www.microsoft.com/startups?WT.mc_id=academic-105485-koreyst)에 지원할 준비가 된 걸지도 몰라요. 우리는 Azure, OpenAI 크레딧, 멘토링 등 많은 것을 제공하고 있어요. 한번 확인해 보세요!

## 복습

대규모 언어 모델에 대해 맞는 말은 무엇일까요?

1. 매번 정확히 같은 응답을 얻어요.
2. 모든 것을 완벽하게 수행하고, 숫자 더하기나 작동하는 코드 생성 등을 잘해요.
3. 같은 프롬프트를 사용해도 응답이 다를 수 있어요. 텍스트나 코드의 첫 초안을 만드는 데 아주 좋지만, 결과를 개선해야 해요.

A: 3번이에요. LLM은 비결정적이라 응답이 달라질 수 있어요. 하지만 온도 설정을 통해 이 변동성을 조절할 수 있죠. 또한 완벽하게 일을 처리할 거라고 기대하면 안 돼요. LLM은 여러분을 위해 힘든 일을 대신해 주는 거예요. 보통 여러분이 점진적으로 개선해야 할 좋은 첫 시도를 제공해 줘요.

## 잘 하셨어요! 계속 나아가봐요

이 수업을 마친 후, [생성형 AI 학습 컬렉션](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)을 확인해 보세요. 생성형 AI에 대한 지식을 계속 높일 수 있을 거예요!

2장으로 넘어가서 [다양한 LLM 유형을 탐색하고 비교](../../../02-exploring-and-comparing-different-llms/translations/ko/README.md?WT.mc_id=academic-105485-koreyst)해 볼까요?
